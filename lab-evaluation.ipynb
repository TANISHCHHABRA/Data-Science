{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cudf\nimport math\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport os\nimport os.path as osp\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn.modules.activation import ReLU\nfrom torch.nn.modules.batchnorm import BatchNorm2d\n\nimport torchvision\nimport torchvision.transforms as ttf\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T07:53:09.856934Z","iopub.execute_input":"2022-03-16T07:53:09.857255Z","iopub.status.idle":"2022-03-16T07:53:14.894289Z","shell.execute_reply.started":"2022-03-16T07:53:09.857176Z","shell.execute_reply":"2022-03-16T07:53:14.893559Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ncloss_weight = 0.001\nbatch_size = 256\nlr = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:53:14.896140Z","iopub.execute_input":"2022-03-16T07:53:14.896537Z","iopub.status.idle":"2022-03-16T07:53:14.901275Z","shell.execute_reply.started":"2022-03-16T07:53:14.896499Z","shell.execute_reply":"2022-03-16T07:53:14.900584Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"../input/11-785-s22-hw2p2-classification/classification/classification/train\"\nVAL_DIR = \"../input/11-785-s22-hw2p2-classification/classification/classification/dev\"\nTEST_DIR = \"../input/11-785-s22-hw2p2-classification/classification/classification/test\"","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:53:14.902531Z","iopub.execute_input":"2022-03-16T07:53:14.903229Z","iopub.status.idle":"2022-03-16T07:53:14.913602Z","shell.execute_reply.started":"2022-03-16T07:53:14.903193Z","shell.execute_reply":"2022-03-16T07:53:14.912875Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_transforms = [ttf.Resize(255), ttf.CenterCrop(224), ttf.ToTensor(), ttf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\nval_transforms = [ttf.Resize(255), ttf.CenterCrop(224), ttf.ToTensor(), ttf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n\ntrain_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=ttf.Compose(train_transforms))\nval_dataset = torchvision.datasets.ImageFolder(VAL_DIR, transform=ttf.Compose(val_transforms))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:53:14.914971Z","iopub.execute_input":"2022-03-16T07:53:14.915482Z","iopub.status.idle":"2022-03-16T07:54:14.470798Z","shell.execute_reply.started":"2022-03-16T07:53:14.915444Z","shell.execute_reply":"2022-03-16T07:54:14.470047Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size,drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:54:14.473449Z","iopub.execute_input":"2022-03-16T07:54:14.473934Z","iopub.status.idle":"2022-03-16T07:54:14.479281Z","shell.execute_reply.started":"2022-03-16T07:54:14.473895Z","shell.execute_reply":"2022-03-16T07:54:14.478549Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class InvertedResidualBlock(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 stride,\n                 expand_ratio):\n        super().__init__()\n        \n        if stride == 1 and in_channels == out_channels:\n            self.do_identity = True\n        else:\n            self.do_identity = False\n        \n        hidden_dim = in_channels * expand_ratio\n        \n        self.feature_mixing = nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size= 1, stride = 1, padding = 0, bias = False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.GELU()\n        )\n        \n        self.spatial_mixing = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size= 3, padding= 1, stride = stride, groups= hidden_dim,\n                      bias = False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.GELU()\n        )\n\n        self.bottleneck_channels = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size= 1, stride= 1, padding= 0, bias= False),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, x):\n        out = self.feature_mixing(x)\n        out = self.spatial_mixing(out)\n        out = self.bottleneck_channels(out)\n\n        if self.do_identity:\n            return x + out\n        else:\n            return out\n\nclass MobileNetV2(nn.Module):\n    def __init__(self, num_classes= 7000, feat_dim = 256):\n        super().__init__()\n\n        self.num_classes = num_classes\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size= 3, stride= 2, padding= 1, bias= False),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 32, kernel_size= 3, stride=1 , padding= 1, groups= 32, bias= False),\n            nn.BatchNorm2d(32),\n            nn.GELU(),\n            nn.Conv2d(32, 16, kernel_size= 1, stride= 1, padding= 0, bias= False),\n            nn.BatchNorm2d(16)\n        )\n\n        self.stage_cfgs = [\n            [6,  24, 2, 2],\n            [6,  32, 3, 2],\n            [6,  64, 4, 2],\n            [6,  96, 3, 1]\n        ]\n        in_channels = 16\n\n        layers = []\n        for curr_stage in self.stage_cfgs:\n            expand_ratio, num_channels, num_blocks, stride = curr_stage\n            \n            for block_idx in range(num_blocks):\n                out_channels = num_channels\n                layers.append(InvertedResidualBlock(\n                    in_channels=in_channels,\n                    out_channels=out_channels,\n                    stride=stride if block_idx == 0 else 1, \n                    expand_ratio=expand_ratio\n                ))\n                in_channels = out_channels \n            \n        self.layers = nn.Sequential(*layers)\n        \n        self.final_block = nn.Sequential(\n            nn.Conv2d(in_channels, 100, kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(100),\n            nn.ReLU6()\n        )\n\n        self.cls_layer = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1,1)),\n            nn.Flatten(),\n            nn.Linear(100, num_classes)\n        )\n        \n        self.feats_layer = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1,1)),\n            nn.Flatten()\n        )     \n\n        self.loss_layer = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1,1)),\n            nn.Flatten(),\n            nn.Linear(100, feat_dim)\n        )\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n    def forward(self,x, return_feats= False, return_embedding = False):\n        out = self.stem(x)\n        out = self.layers(out)\n        out = self.final_block(out)\n        \n        if return_embedding:\n          out2 = self.loss_layer(out)\n          out = self.cls_layer(out)\n          return out, out2\n        if return_feats:\n          out3 = self.feats_layer(out)\n          return out3\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:54:14.480881Z","iopub.execute_input":"2022-03-16T07:54:14.481387Z","iopub.status.idle":"2022-03-16T07:54:14.507421Z","shell.execute_reply.started":"2022-03-16T07:54:14.481350Z","shell.execute_reply":"2022-03-16T07:54:14.506690Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CenterLoss(nn.Module):\n    def __init__(self, num_classes, feat_dim, device=torch.device('cuda')):\n        super(CenterLoss, self).__init__()\n        self.num_classes = num_classes\n        self.feat_dim = feat_dim\n        self.device = device\n        \n        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).to(self.device))\n\n    def forward(self, x, labels):\n        batch_size = x.size(0)\n        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n        distmat.addmm_(1, -2, x, self.centers.t())\n\n        classes = torch.arange(self.num_classes).long().to(self.device)\n        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n\n        dist = []\n        for i in range(batch_size):\n            value = distmat[i][mask[i]]\n            value = value.clamp(min=1e-12, max=1e+12)\n            dist.append(value)\n        dist = torch.cat(dist)\n        loss = dist.mean()\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:54:14.509806Z","iopub.execute_input":"2022-03-16T07:54:14.510429Z","iopub.status.idle":"2022-03-16T07:54:14.521878Z","shell.execute_reply.started":"2022-03-16T07:54:14.510390Z","shell.execute_reply":"2022-03-16T07:54:14.521230Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = MobileNetV2()\nmodel.cuda()\nnum_trainable_parameters = 0\nfor p in model.parameters():\n    num_trainable_parameters += p.numel()\nprint(\"Number of Params: {}\".format(num_trainable_parameters))\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnum_classes = len(train_dataset.classes)\nfeat_dim = 256\ncriterion_label = torch.nn.CrossEntropyLoss()\ncriterion_closs = CenterLoss(num_classes, feat_dim, device)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:54:14.524784Z","iopub.execute_input":"2022-03-16T07:54:14.525043Z","iopub.status.idle":"2022-03-16T07:54:19.364542Z","shell.execute_reply.started":"2022-03-16T07:54:14.525014Z","shell.execute_reply":"2022-03-16T07:54:19.363767Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss() \noptimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\nscaler = torch.cuda.amp.GradScaler()\n\ndef valid(model, val_loader):\n    model.eval()\n    \n    num_correct = 0\n    for i, (x, y) in enumerate(val_loader):\n\n        x = x.cuda()\n        y = y.cuda()\n\n        with torch.no_grad():\n            outputs, features = model(x, return_embedding = True)\n\n        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n       \n    valid_acc = 100 * num_correct / len(val_dataset)\n    return valid_acc\n\nfor epoch in range(1, epochs +1):\n    model.train()\n    \n    num_correct = 0\n    total_loss = 0\n\n    for i, (x, y) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        x = x.cuda()\n        y = y.cuda()\n        \n        with torch.cuda.amp.autocast():     \n            outputs, features = model(x, return_embedding = True)\n            l_loss = criterion_label(outputs, y)\n            c_loss = criterion_closs(features.float(), y)\n            loss = l_loss + closs_weight * c_loss\n          \n        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n        total_loss += float(loss)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n    \n    valid_acc = valid(model, val_loader)\n    \n    print('Iteration:',str(epoch))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:54:19.365874Z","iopub.execute_input":"2022-03-16T07:54:19.366507Z","iopub.status.idle":"2022-03-16T08:25:49.914315Z","shell.execute_reply.started":"2022-03-16T07:54:19.366470Z","shell.execute_reply":"2022-03-16T08:25:49.913447Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ClassificationTestSet(Dataset):\n    def __init__(self, data_dir, transforms):\n        self.data_dir = data_dir\n        self.transforms = transforms\n        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n\n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, idx):\n        return self.transforms(Image.open(self.img_paths[idx]))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:25:49.915446Z","iopub.execute_input":"2022-03-16T08:25:49.916225Z","iopub.status.idle":"2022-03-16T08:25:49.923540Z","shell.execute_reply.started":"2022-03-16T08:25:49.916185Z","shell.execute_reply":"2022-03-16T08:25:49.922643Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationTestSet(TEST_DIR, ttf.Compose(val_transforms))\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                         drop_last=False, num_workers=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:25:49.924838Z","iopub.execute_input":"2022-03-16T08:25:49.925141Z","iopub.status.idle":"2022-03-16T08:25:50.924651Z","shell.execute_reply.started":"2022-03-16T08:25:49.925106Z","shell.execute_reply":"2022-03-16T08:25:50.923883Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(), './model')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:25:50.925807Z","iopub.execute_input":"2022-03-16T08:25:50.927726Z","iopub.status.idle":"2022-03-16T08:25:50.932280Z","shell.execute_reply.started":"2022-03-16T08:25:50.927692Z","shell.execute_reply":"2022-03-16T08:25:50.930725Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndevice = torch.device(\"cuda\")\nmodel = MobileNetV2()\nmodel.load_state_dict(torch.load('../input/dslab/model'))\n#model.to(device)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:25:50.933601Z","iopub.execute_input":"2022-03-16T08:25:50.935207Z","iopub.status.idle":"2022-03-16T08:25:50.945212Z","shell.execute_reply.started":"2022-03-16T08:25:50.935173Z","shell.execute_reply":"2022-03-16T08:25:50.944136Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.eval()\nimg_path_list = list(test_dataset.img_paths)\nres = []\nnames = []\nfor i, (x) in enumerate(test_loader):\n    x = x.cuda()\n    with torch.no_grad():\n        outputs = model(x,return_embedding=True)[0]\n    pred_y = torch.argmax(outputs, axis=1)\n    res.extend(pred_y.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:25:50.948590Z","iopub.execute_input":"2022-03-16T08:25:50.948897Z","iopub.status.idle":"2022-03-16T08:31:31.262201Z","shell.execute_reply.started":"2022-03-16T08:25:50.948862Z","shell.execute_reply":"2022-03-16T08:31:31.261001Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"id = []\nfor i in range(len(test_dataset)):\n    id.append(str(i).zfill(6)+\".jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:31:31.264055Z","iopub.execute_input":"2022-03-16T08:31:31.264367Z","iopub.status.idle":"2022-03-16T08:31:31.290844Z","shell.execute_reply.started":"2022-03-16T08:31:31.264322Z","shell.execute_reply":"2022-03-16T08:31:31.290026Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"output = cudf.DataFrame({'id': id, 'label': res})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:31:31.292457Z","iopub.execute_input":"2022-03-16T08:31:31.293023Z","iopub.status.idle":"2022-03-16T08:31:31.345255Z","shell.execute_reply.started":"2022-03-16T08:31:31.292978Z","shell.execute_reply":"2022-03-16T08:31:31.344317Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:31:31.346795Z","iopub.execute_input":"2022-03-16T08:31:31.347091Z","iopub.status.idle":"2022-03-16T08:31:31.419702Z","shell.execute_reply.started":"2022-03-16T08:31:31.347056Z","shell.execute_reply":"2022-03-16T08:31:31.418871Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}